{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze Trump's tweet I will be using a csv data containing tweets from 2009 to 2020. \n",
    "\n",
    "I will be performing the following tasks:\n",
    "* Data Processing\n",
    "    * Yearly Corpus\n",
    "    * Document Term Matrix\n",
    "* Exploratory Data Analysis\n",
    "* Sentiment Analysis\n",
    "    * TextBlob\n",
    "* Topic Modelling\n",
    "    * Latent Dirichlet Allocation\n",
    "* Text Generation \n",
    "    * Markov's Chain \n",
    "    * Recurrent Neural Network\n",
    "\n",
    "<b>Note:</b> Trump's tweet are only until June 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1698308935</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701461182</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1737479987</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1741160716</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1773561338</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               link  \\\n",
       "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
       "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
       "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
       "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
       "\n",
       "                                             content                 date  \\\n",
       "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 13:54:25   \n",
       "1  Donald Trump will be appearing on The View tom...  2009-05-04 20:00:10   \n",
       "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 08:38:08   \n",
       "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 15:40:15   \n",
       "4  \"My persona will never be that of a wallflower...  2009-05-12 09:07:28   \n",
       "\n",
       "   retweets  favorites mentions hashtags  \n",
       "0       510        917      NaN      NaN  \n",
       "1        34        267      NaN      NaN  \n",
       "2        13         19      NaN      NaN  \n",
       "3        11         26      NaN      NaN  \n",
       "4      1375       1945      NaN      NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/realdonaldtrump.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting date from string to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.astype({'date':'datetime64[ns]'})\n",
    "type(data['date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Excluding irrelevant data for this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                date  \\\n",
       "0  Be sure to tune in and watch Donald Trump on L... 2009-05-04 13:54:25   \n",
       "1  Donald Trump will be appearing on The View tom... 2009-05-04 20:00:10   \n",
       "2  Donald Trump reads Top Ten Financial Tips on L... 2009-05-08 08:38:08   \n",
       "3  New Blog Post: Celebrity Apprentice Finale and... 2009-05-08 15:40:15   \n",
       "4  \"My persona will never be that of a wallflower... 2009-05-12 09:07:28   \n",
       "\n",
       "   retweets  favorites  \n",
       "0       510        917  \n",
       "1        34        267  \n",
       "2        13         19  \n",
       "3        11         26  \n",
       "4      1375       1945  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluding id, link, mentions, hashtags\n",
    "\n",
    "data = data[['content', 'date', 'retweets', 'favorites']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform data science operations on data, it has to be cleaned first.\n",
    "\n",
    "Cleaning of data involves the following:\n",
    "    * Convert the text into lowercase\n",
    "    * Removal of brackets\n",
    "    * Removal of mentions\n",
    "    * Removal of links\n",
    "    * Removal of punctuation\n",
    "    * Removal of numeric and alphanumeric words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    \n",
    "    # Convert all tweets to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # removing small bracket\n",
    "    text = re.sub('\\(', '', text)\n",
    "    text = re.sub('\\)', '', text)\n",
    "    \n",
    "    # removing mentions\n",
    "    text = re.sub('(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@(\\s[A-Za-z]+[A-Za-z0-9_]+)', '', text)\n",
    "    \n",
    "    # removing links\n",
    "    text = re.sub(r'http\\S+', \"\", text)\n",
    "    \n",
    "    # removing links\n",
    "    text = re.sub(r\"'s\", \"\", text)\n",
    "    \n",
    "    # replacing -- with one white-space \n",
    "    text = re.sub('--', ' ', text)\n",
    "    \n",
    "    #removing punctuation\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    #removing numeric and alpha-numeric characters\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be sure to tune in and watch donald trump on l...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>donald trump will be appearing on the view tom...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald trump reads top ten financial tips on l...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new blog post celebrity apprentice finale and ...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my persona will never be that of a wallflower ...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                date  \\\n",
       "0  be sure to tune in and watch donald trump on l... 2009-05-04 13:54:25   \n",
       "1  donald trump will be appearing on the view tom... 2009-05-04 20:00:10   \n",
       "2  donald trump reads top ten financial tips on l... 2009-05-08 08:38:08   \n",
       "3  new blog post celebrity apprentice finale and ... 2009-05-08 15:40:15   \n",
       "4  my persona will never be that of a wallflower ... 2009-05-12 09:07:28   \n",
       "\n",
       "   retweets  favorites  \n",
       "0       510        917  \n",
       "1        34        267  \n",
       "2        13         19  \n",
       "3        11         26  \n",
       "4      1375       1945  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data\n",
    "data_clean['content'] = data['content'].apply(round1)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Round 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Non-English words from the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be sure to tune in and watch trump on late nig...</td>\n",
       "      <td>2009-05-04 13:54:25</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump will be on the view tomorrow morning to ...</td>\n",
       "      <td>2009-05-04 20:00:10</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trump top ten financial on late show with very...</td>\n",
       "      <td>2009-05-08 08:38:08</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new post celebrity apprentice finale and learn...</td>\n",
       "      <td>2009-05-08 15:40:15</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my persona will never be that of a wallflower ...</td>\n",
       "      <td>2009-05-12 09:07:28</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content                date  \\\n",
       "0  be sure to tune in and watch trump on late nig... 2009-05-04 13:54:25   \n",
       "1  trump will be on the view tomorrow morning to ... 2009-05-04 20:00:10   \n",
       "2  trump top ten financial on late show with very... 2009-05-08 08:38:08   \n",
       "3  new post celebrity apprentice finale and learn... 2009-05-08 15:40:15   \n",
       "4  my persona will never be that of a wallflower ... 2009-05-12 09:07:28   \n",
       "\n",
       "   retweets  favorites  \n",
       "0       510        917  \n",
       "1        34        267  \n",
       "2        13         19  \n",
       "3        11         26  \n",
       "4      1375       1945  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "\n",
    "def clean_text_round2(text):\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha())\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)\n",
    "\n",
    "data_clean['content'] = data_clean['content'].apply(round2)\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pickle Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.to_pickle('data/data_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Document Term Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Document Term Matrix is a matrix which describes the frequency of terms that occur in a collection of documents. \n",
    "* In DTM rows represents documents and columns reperesents terms.\n",
    "* In this case, each tweets of a year is considered as a document. \n",
    "* To create a DTM, corpus is required which has been created in the above cell.\n",
    "* This corpus is then used to create a Count Vectorizer which is then used to create DTM.\n",
    "* Using CountVectorizer stop words can also be eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>be sure to tune in and watch trump on late nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>celebrity apprentice to outstanding list of se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>watch me on late night with jimmy tomorrow nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>my interview the make great again filing and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>and the are laughing at the deal they just got...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                         transcript\n",
       "0  2009  be sure to tune in and watch trump on late nig...\n",
       "1  2010  celebrity apprentice to outstanding list of se...\n",
       "2  2011  watch me on late night with jimmy tomorrow nig...\n",
       "3  2012  my interview the make great again filing and t...\n",
       "4  2013  and the are laughing at the deal they just got..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['year', 'transcript']\n",
    "corpus_yearly = pd.DataFrame(columns=columns)\n",
    "\n",
    "group = data_clean.groupby(data_clean.date.dt.year)\n",
    "\n",
    "year_list = []\n",
    "transcript_list = []\n",
    "\n",
    "for year, group_data in group:\n",
    "    text = ' '.join(group_data['content'])\n",
    "    year_list.append(year)\n",
    "    transcript_list.append(text)\n",
    "\n",
    "corpus_yearly['year'] = year_list\n",
    "corpus_yearly['transcript'] = transcript_list\n",
    "\n",
    "corpus_yearly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbas</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abide</th>\n",
       "      <th>abiding</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>...</th>\n",
       "      <th>zac</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zee</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 9495 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandon  abandoned  abbas  abhor  abide  abiding  ability  abject  able  \\\n",
       "year                                                                            \n",
       "2009        0          0      0      0      0        0        0       0     0   \n",
       "2010        0          0      0      0      0        0        0       0     0   \n",
       "2011        0          2      0      0      0        0        1       0     0   \n",
       "2012        1          3      0      0      0        0        3       1    13   \n",
       "2013        2          8      0      1      0        0        8       0    17   \n",
       "2014        0          0      0      0      1        0        8       0    16   \n",
       "2015        1          1      0      0      0        0        8       0    22   \n",
       "2016        2          1      0      0      0        0        3       0    12   \n",
       "2017        0          1      1      0      0        0        1       0    10   \n",
       "2018        3          5      0      0      0        0        2       0    19   \n",
       "2019        0          2      0      0      0        0        0       0    33   \n",
       "2020        2          1      0      0      0        1        1       0    11   \n",
       "\n",
       "      abnormally  ...   zac  zeal  zee  zero  zimbabwe  zip  zone  zoning  \\\n",
       "year              ...                                                       \n",
       "2009           0  ...     0     0    0     0         0    0     1       0   \n",
       "2010           0  ...     0     0    0     0         0    0     0       0   \n",
       "2011           0  ...     0     0    0     1         0    0     0       0   \n",
       "2012           0  ...     0     0    0    14         0    0     0       0   \n",
       "2013           1  ...     0     1    1    21         0    0     4       0   \n",
       "2014           0  ...     0     0    0    15         0    1     4       0   \n",
       "2015           0  ...     1     0    0    15         1    1     1       0   \n",
       "2016           0  ...     0     0    0    24         0    0     0       0   \n",
       "2017           0  ...     0     0    0    11         0    0     1       0   \n",
       "2018           0  ...     0     0    0    17         0    0     1       0   \n",
       "2019           0  ...     0     0    0    55         0    0     5       1   \n",
       "2020           0  ...     0     0    0    19         0    0     0       0   \n",
       "\n",
       "      zoo  zoom  \n",
       "year             \n",
       "2009    0     0  \n",
       "2010    0     0  \n",
       "2011    0     0  \n",
       "2012    0     0  \n",
       "2013    0     0  \n",
       "2014    0     0  \n",
       "2015    0     1  \n",
       "2016    0     0  \n",
       "2017    1     0  \n",
       "2018    0     0  \n",
       "2019    0     2  \n",
       "2020    0     0  \n",
       "\n",
       "[12 rows x 9495 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words = 'english')\n",
    "data_cv = cv.fit_transform(corpus_yearly.transcript)\n",
    "dtm_yearly = pd.DataFrame(data_cv.toarray(), columns = cv.get_feature_names())\n",
    "dtm_yearly.index = corpus_yearly.year\n",
    "dtm_yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pickle Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_yearly.to_pickle('data/dtm_yearly.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pickle Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open('data/cv.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Yearly Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A yearly corpus will be formed by joining all the tweets of every year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = data_clean.groupby(data_clean.date.dt.year)\n",
    "\n",
    "corpus_dict = {}\n",
    "\n",
    "for year, group_data in group:\n",
    "    text = ' '.join(group_data['content'])\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha())\n",
    "    corpus_dict[year] = [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>be sure to tune in and watch trump on late nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>celebrity apprentice to outstanding list of se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>watch me on late night with jimmy tomorrow nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>my interview the make great again filing and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>and the are laughing at the deal they just got...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>today is the first day of the rest of your lif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>for president the club was amazing tonight eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>happy new year from thank you to my great fami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>well the new year we will together make great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>the united foolishly given more than billion i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>a very good and talented guy a great new book ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>best equipment military in the world on site q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript\n",
       "2009  be sure to tune in and watch trump on late nig...\n",
       "2010  celebrity apprentice to outstanding list of se...\n",
       "2011  watch me on late night with jimmy tomorrow nig...\n",
       "2012  my interview the make great again filing and t...\n",
       "2013  and the are laughing at the deal they just got...\n",
       "2014  today is the first day of the rest of your lif...\n",
       "2015  for president the club was amazing tonight eve...\n",
       "2016  happy new year from thank you to my great fami...\n",
       "2017  well the new year we will together make great ...\n",
       "2018  the united foolishly given more than billion i...\n",
       "2019  a very good and talented guy a great new book ...\n",
       "2020  best equipment military in the world on site q..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_yearly = pd.DataFrame.from_dict(corpus_dict).transpose()\n",
    "corpus_yearly.columns = ['transcript']\n",
    "corpus_yearly = corpus_yearly.sort_index()\n",
    "corpus_yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pickle yearly corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_yearly.to_pickle('data/corpus_yearly.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
